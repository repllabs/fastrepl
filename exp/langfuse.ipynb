{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq \"fastrepl==0.0.17\" \"langfuse>=1.0.35\" langchain chromadb datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastrepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastrepl.Dataset({\n",
       "    features: ['question'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"repllabs/questions_how_to_do_great_work\", split=\"processed\")\n",
    "ds = ds.remove_columns([\"model\"])\n",
    "ds = ds.shuffle(seed=12)\n",
    "ds = ds.select(range(30))\n",
    "ds = fastrepl.Dataset.from_hf(ds)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_HOST = \"https://cloud.langfuse.com\"\n",
    "ENV_SECRET_KEY = \"\"\n",
    "ENV_PUBLIC_KEY = \"\"\n",
    "\n",
    "%env OPENAI_API_KEY=\n",
    "ENV_OPENAI_API_KEY = \"\"\n",
    "\n",
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_NAME = \"how-to-do-great-work4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.model import CreateDatasetRequest, CreateDatasetItemRequest\n",
    "\n",
    "langfuse.create_dataset(CreateDatasetRequest(name=DS_NAME))\n",
    "\n",
    "for row in ds:\n",
    "    langfuse.create_dataset_item(\n",
    "        CreateDatasetItemRequest(\n",
    "            datasetName=DS_NAME,\n",
    "            input=row[\"question\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastrepl.Dataset({\n",
       "    features: ['_lf_item_index', 'question'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse_ds = langfuse.get_dataset(name=DS_NAME)\n",
    "ds = fastrepl.Dataset.from_langfuse(langfuse_ds)\n",
    "\n",
    "ds = ds.rename_column(\"inputs\", \"question\")\n",
    "ds = ds.remove_column(\"expected_outputs\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_docs(url: str) -> list[str]:\n",
    "    from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "    loader = WebBaseLoader(url)\n",
    "    data = loader.load()\n",
    "\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    docs = splitter.split_documents(data)\n",
    "    return [doc.page_content for doc in docs[1:]]\n",
    "\n",
    "\n",
    "def create_collection(name: str, docs: list[str]):\n",
    "    import chromadb\n",
    "    from chromadb.utils import embedding_functions\n",
    "\n",
    "    client = chromadb.EphemeralClient()\n",
    "    collection = client.create_collection(\n",
    "        name=name,\n",
    "        get_or_create=True,\n",
    "        embedding_function=embedding_functions.OpenAIEmbeddingFunction(\n",
    "            api_key=ENV_OPENAI_API_KEY\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    collection.add(documents=docs, ids=[str(i) for i in range(len(docs))])\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "from langfuse.model import CreateTrace, InitialSpan, InitialGeneration, Usage\n",
    "\n",
    "import litellm\n",
    "from datetime import datetime\n",
    "from chromadb import Collection\n",
    "\n",
    "\n",
    "class QA:\n",
    "    def __init__(self, collection: Collection) -> None:\n",
    "        self.collection = collection\n",
    "        self.trace_ids = []\n",
    "        self.generation_ids = []\n",
    "\n",
    "    def retrieve_docs(self, question: str, traceId: Optional[str] = None) -> List[str]:\n",
    "        startRetrieval = datetime.now()\n",
    "        result = self.collection.query(query_texts=[question], n_results=1)\n",
    "        contexts = result[\"documents\"][0]\n",
    "        endRetrieval = datetime.now()\n",
    "\n",
    "        if traceId is not None:\n",
    "            langfuse.span(\n",
    "                InitialSpan(\n",
    "                    traceId=traceId,\n",
    "                    name=\"contexts-retrieval\",\n",
    "                    startTime=startRetrieval,\n",
    "                    endTime=endRetrieval,\n",
    "                    input=question,\n",
    "                    output=contexts,\n",
    "                )\n",
    "            )\n",
    "        return contexts\n",
    "\n",
    "    def generate(\n",
    "        self, question: str, contexts: List[str], traceId: Optional[str] = None\n",
    "    ) -> str:\n",
    "        model = \"gpt-3.5-turbo\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"Answer the question using the contexts if needed. Contexts: {contexts}\n",
    "Do not make things up. Use less than 30 words.\"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Question: {question}\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        startGeneration = datetime.now()\n",
    "        res = litellm.completion(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            api_key=ENV_OPENAI_API_KEY,\n",
    "        )\n",
    "        endGeneration = datetime.now()\n",
    "\n",
    "        if traceId is not None:\n",
    "            generation = langfuse.generation(\n",
    "                InitialGeneration(\n",
    "                    traceId=traceId,\n",
    "                    name=\"answer-generation\",\n",
    "                    startTime=startGeneration,\n",
    "                    endTime=endGeneration,\n",
    "                    model=model,\n",
    "                    prompt=messages,\n",
    "                    completion=res[\"choices\"][0][\"message\"][\"content\"],\n",
    "                    usage=Usage(\n",
    "                        prompt_tokens=res[\"usage\"][\"prompt_tokens\"],\n",
    "                        completion_tokens=res[\"usage\"][\"completion_tokens\"],\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "            self.generation_ids.append(generation.id)\n",
    "\n",
    "        return res[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    def run(self, question: str, trace=True):\n",
    "        traceId = (\n",
    "            langfuse.trace(CreateTrace(name=\"qa-pg-how-to-do-great-work\")).id\n",
    "            if trace\n",
    "            else None\n",
    "        )\n",
    "        self.trace_ids.append(traceId)\n",
    "\n",
    "        contexts = self.retrieve_docs(question, traceId)\n",
    "        response = self.generate(question, contexts, traceId)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = create_docs(\"http://paulgraham.com/greatwork.html\")\n",
    "collection = create_collection(\"how-to-do-great-work\", docs)\n",
    "\n",
    "qa = QA(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57895e02f1144c969d3bb5add5f28fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fastrepl.Dataset({\n",
       "    features: ['_lf_item_index', 'question', 'answer'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = qa.run\n",
    "args_list = [(q,) for q in ds[\"question\"]]\n",
    "result = fastrepl.local_runner(fn=fn, output_feature=\"answer\").run(args_list=args_list)\n",
    "\n",
    "ds = ds.add_column(\"answer\", result[\"answer\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastrepl.Dataset({\n",
       "    features: ['_lf_item_index', 'question', 'answer', '_lf_trace_id', '_lf_generation_id'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.add_column(\"_lf_trace_id\", qa.trace_ids)\n",
    "ds = ds.add_column(\"_lf_generation_id\", qa.generation_ids)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d10c38654e5422dade2ab13187dc116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fastrepl.Dataset({\n",
       "    features: ['_lf_item_index', 'question', 'answer', '_lf_trace_id', '_lf_generation_id', 'contexts'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = qa.retrieve_docs\n",
    "args_list = [(q,) for q in ds[\"question\"]]\n",
    "result = fastrepl.local_runner(fn=fn, output_feature=\"contexts\").run(\n",
    "    args_list=args_list\n",
    ")\n",
    "\n",
    "ds.add_column(\"contexts\", result[\"contexts\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c393dc0beafc4c87ad4e6c6e5ebd4ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = fastrepl.RAGEvaluator(\n",
    "    node=fastrepl.RAGAS(metric=\"Faithfulness\"),\n",
    ")\n",
    "\n",
    "result = fastrepl.local_runner(evaluator=evaluator, dataset=ds).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastrepl.Dataset({\n",
       "    features: ['_lf_item_index', 'question', 'answer', '_lf_trace_id', '_lf_generation_id', 'contexts', 'result'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.model import InitialScore\n",
    "\n",
    "\n",
    "def run_experiment(experiment_name: str, metric_name: str):\n",
    "    for row in result:\n",
    "        index: int = row[\"_lf_item_index\"]\n",
    "        traceId: str = str(row[\"_lf_trace_id\"])\n",
    "        generationId: str = row[\"_lf_generation_id\"]\n",
    "        score: float = row[\"result\"]\n",
    "\n",
    "        langfuse_ds.items[index].link(generationId, experiment_name)\n",
    "        langfuse.score(\n",
    "            InitialScore(\n",
    "                name=metric_name,\n",
    "                traceId=traceId,\n",
    "                observationId=generationId,\n",
    "                value=score,\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "run_experiment(\"test_experiment-2\", \"ragas-faithfulness\")\n",
    "langfuse.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
