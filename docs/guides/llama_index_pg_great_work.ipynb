{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Evaluation on LlamaIndex built-in evaluation\n",
    "\n",
    "`LlamaIndex` has good documentaion and [built-in support](https://gpt-index.readthedocs.io/en/latest/core_modules/supporting_modules/evaluation/usage_pattern.html) for evaluation.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq llama_index==\"0.8.22\" pydantic nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleWebPageReader,\n",
    "    ServiceContext,\n",
    "    LLMPredictor,\n",
    ")\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Documents\n",
    "\n",
    "[How to do great work](http://paulgraham.com/greatwork.html) is wonderful blog post by Paul Graham. With `SimpleWebPageReader`, we can easily load the documents and get the query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"http://paulgraham.com/greatwork.html\"]\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(urls)\n",
    "\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents, service_context=service_context\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow your heart.\n"
     ]
    }
   ],
   "source": [
    "query = \"To do great work, should I follow my heart or my head?\"\n",
    "response = query_engine.query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, for sure. Let's look into the sources too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: 5f29d164-ca93-4480-bb22-dd38745dca3c): This is how practically everyone who's done great work\n",
      "has done it, from painters to physicists.Steps two and four will require hard work.It may not be possible to prove\n",
      "that you have to work hard to do great things, but the empirical evidence is\n",
      "...\n",
      "\n",
      "> Source (Doc id: 50bd6bd7-f8c3-443c-a6f3-c1198f62bfa7): Since it matters so much for this cycle to be\n",
      "running in the right direction, it can be a good idea to switch to easier work\n",
      "when you're stuck, just so you start to get something done.One of the biggest mistakes ambitious people make is to allow s...\n"
     ]
    }
   ],
   "source": [
    "print(response.get_formatted_sources(length=250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Questions\n",
    "\n",
    "To run an evaluation on a QA system, we need questions. The good thing is that `LllamaIndex` has `DatasetGenerator`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the three qualities that the work you choose needs to have according to the author?', 'How does the author suggest figuring out what to work on?']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.evaluation import DatasetGenerator\n",
    "\n",
    "data_generator = DatasetGenerator.from_documents(documents)\n",
    "questions = data_generator.generate_questions_from_nodes(num=2)\n",
    "\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import QueryResponseEvaluator\n",
    "\n",
    "evaluator = QueryResponseEvaluator(service_context=service_context)\n",
    "\n",
    "results = []\n",
    "\n",
    "for query in _ds[\"question\"]:\n",
    "    response = query_engine.query(query)\n",
    "    result = evaluator.evaluate(query, response)\n",
    "    results.append(result)\n",
    "\n",
    "result2 = Dataset.from_dict({\"input\": _ds[\"question\"], \"prediction\": results})\n",
    "result2.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/jerryjliu/llama_index/blob/9acd9297860824ebc2c9c47358c05f387c62cff5/llama_index/evaluation/base.py#L226\n",
    "\n",
    "[QueryResponseEvaluator](https://gpt-index.readthedocs.io/en/latest/core_modules/supporting_modules/evaluation/usage_pattern.html#evaluting-query-response-for-answer-quality) checks if the synthesized response matches the query + any source context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37c8276595f49f5989b0ec3c86625b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from datasets import Dataset\n",
    "from llama_index import Response\n",
    "\n",
    "import fastrepl\n",
    "\n",
    "\n",
    "def get_context(response: Response) -> List[str]:\n",
    "    return [context_info.node.get_content() for context_info in response.source_nodes]\n",
    "\n",
    "\n",
    "def get_input(query: str, r: Response) -> str:\n",
    "    response = r.response\n",
    "    context = get_context(r)\n",
    "    return f\"Query: {query}, Response: {response}, Context: {context}\"\n",
    "\n",
    "\n",
    "_ds = Dataset.from_dict({\"question\": questions})\n",
    "\n",
    "\n",
    "def transform(row):\n",
    "    query = row[\"question\"]\n",
    "    response = query_engine.query(query)\n",
    "    row[\"input\"] = get_input(query, response)\n",
    "    return row\n",
    "\n",
    "\n",
    "ds = _ds.map(transform, remove_columns=[\"question\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6799bcc3a2db421aaf681033ffdb06a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Query: What are the three qualities that the w...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Query: How does the author suggest figuring ou...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Query: What are the four steps the author outl...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Query: Why does the author emphasize the impor...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Query: How does the author suggest making your...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input prediction\n",
       "0  Query: What are the three qualities that the w...         NO\n",
       "1  Query: How does the author suggest figuring ou...        YES\n",
       "2  Query: What are the four steps the author outl...         NO\n",
       "3  Query: Why does the author emphasize the impor...         NO\n",
       "4  Query: How does the author suggest making your...        YES"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = fastrepl.SimpleEvaluator(\n",
    "    pipeline=[\n",
    "        fastrepl.LLMClassificationHead(\n",
    "            model=\"gpt-4\",\n",
    "            context=\"You will receive text containing query, response, and context information. You should evaluate the response based on the query and context.\",\n",
    "            labels={\n",
    "                \"YES\": \"response for the query is in line with the context.\",\n",
    "                \"NO\": \"response for the query is NOT in line with the context.\",\n",
    "            },\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = fastrepl.local_runner(evaluator, ds).run()\n",
    "result.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
