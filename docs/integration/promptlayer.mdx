---
title: Promptlayer
description: Prompt engineering platform that helps you with robust monitoring, prompt versioning, cost analysis, and evaluation.
---

`Promptlayer` provides a way to [score](https://docs.promptlayer.com/why-promptlayer/evaluation-and-ranking#scoring) each request you made.
With `fastrepl`, you can use LLM to help with this process. This is especially useful when you want to `A/B test` your prompts.

## Setup

```
pip install -qq "fastrepl>=0.0.20" "promptlayer"
```

```python
import promptlayer
PL_API_KEY = "pl_XX" # Promptlayer API key
promptlayer.api_key=PL_API_KEY

openai = promptlayer.openai
openai.api_key = "sk-XX" # OpenAI API key
```

Here, we are using `Promptlayer`'s drop-in replacement for `openai`. If you are looking for way to use various models, checkout [LiteLLM's PromptLayer Integration](https://docs.litellm.ai/docs/observability/promptlayer_integration).

```python
response, request_id = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "hi"},
    ],
    return_pl_id=True,
)

print(response.choices[0].message.content, request_id)
# Hello! How can I assist you today? 12982004
# Go to https://promptlayer.com/request/12982004 for details
```

`request_id` is used for scoring, which we will cover in the next section.

## General Evaluation
```python
import fastrepl


evaluator = fastrepl.SimpleEvaluator(
    node=fastrepl.LLMGradingHead(
        model="gpt-3.5-turbo",
        context="Grade how much happiness does the text contain.",
        number_from=0,
        number_to=5,
        references=[("happy!", 5), ("sad...", "0")], # optional
    )
)

runner = fastrepl.pl_runner(evaluator=evaluator, api_key=PL_API_KEY)
```

```python
def completion_with_scoring():
    response, request_id = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "hi"},
        ],
        return_pl_id=True,
    )
    result = response.choices[0].text

    ds = fastrepl.Dataset.from_dict(
        {"sample": [result], "request_id": [request_id]}
    )
    runner.run(ds) # use_threading=True by default

completion_with_scoring()
```

## RAG evaluation

It is similar to `General Evaluation`, but we use `RAGEvaluator` instead of `SimpleEvaluator`.

We have detailed [notebook](https://colab.research.google.com/github/repllabs/fastrepl/blob/main/examples/promptlayer.ipynb), and [video](https://www.loom.com/share/9f095b5a31544cd69e54f99f1bf03409?sid=2d28913e-af2f-4a87-87eb-b7879774b622) explaining it.

