{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"fastrepl==0.0.6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find all releases [here](https://pypi.org/project/fastrepl).\n",
    "\n",
    "## Setup FastREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using it in a script\n",
    "import fastrepl\n",
    "\n",
    "# When using it in a notebook\n",
    "import fastrepl.repl as fastrepl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "We will use [daily_dialog](https://huggingface.co/datasets/daily_dialog) from Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55399275389f4cb0a50cc5ea8f200d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"daily_dialog\", split=\"test\")\n",
    "ds = ds.shuffle(4)\n",
    "ds = ds.select(range(10))\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    return re.sub(r\"\\s+([,.'!?])\", r\"\\1\", text.strip())\n",
    "\n",
    "\n",
    "def get_input(row):\n",
    "    msgs = [clean(msg) for msg in row[\"dialog\"]]\n",
    "    row[\"sample\"] = \"\\n\".join(msgs)\n",
    "    row[\"context\"] = \"\"\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "ds = ds.map(get_input, remove_columns=[\"dialog\", \"act\", \"emotion\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluator\n",
    "\n",
    "Here, we are doing simple classifiction, but there are two interesting points.\n",
    "\n",
    "1. You can pass nearly any model for evaluation. (Thanks to [LiteLLM](https://github.com/BerriAI/litellm)).\n",
    "2. **`fastrepl` enhances accuracy by reducing [bias](/guides/dealing_with_bias.md)**. `position_debias_strategy` is one example, which ensures that the order of labels doesn't affect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = fastrepl.SimpleEvaluator.from_node(\n",
    "    fastrepl.LLMClassificationHead(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        context=\"You will receive casual conversation between two people.\",\n",
    "        labels={\n",
    "            \"FUN\": \"at least one of the two people try to be funny and entertain.\",\n",
    "            \"NOT_FUN\": \"given conversation lacks humor or entertainment value.\",\n",
    "        },\n",
    "        position_debias_strategy=\"consensus\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluator\n",
    "\n",
    "Here are some notes about running the evaluator:\n",
    "\n",
    "1. `ThreadPool` is used to make it faster (controlled by the `NUM_THREADS` [environment variable](/getting_started/env.md)).\n",
    "2. Any errors from different LLM providers are properly handled and retried with backoff if necessary.\n",
    "3. Since we passed `num=2` to `run()`, it will execute same evaluation twice, and return two results. If there are high inconsistency between the two, you'll see [InconsistentPredictionWarning](/miscellaneous/warnings_and_errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a5265b2ed7454d9630321da4e64363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'prediction'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = fastrepl.LocalRunner(evaluator=evaluator, dataset=ds).run(num=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>context</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would you like to take a look at the menu, sir...</td>\n",
       "      <td></td>\n",
       "      <td>[FUN, FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Help! Help!\\nWhat's the matter?</td>\n",
       "      <td></td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whatever we do, we should do it above board.\\n...</td>\n",
       "      <td></td>\n",
       "      <td>[FUN, FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>May I see your passport, please?\\nCertainly. H...</td>\n",
       "      <td></td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We're thinking about going to America.\\nHave y...</td>\n",
       "      <td></td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Do you believe in UFOs?\\nOf course, they are o...</td>\n",
       "      <td></td>\n",
       "      <td>[FUN, FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What do you think about the equipment in our c...</td>\n",
       "      <td></td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How was your business trip?\\nGreat - they wine...</td>\n",
       "      <td></td>\n",
       "      <td>[FUN, FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hello, Parker. How ’ s everything?\\nCan ’ t co...</td>\n",
       "      <td></td>\n",
       "      <td>[FUN, FUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Our toner cartridges are already out of ink......</td>\n",
       "      <td></td>\n",
       "      <td>[NOT_FUN, NOT_FUN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample context  \\\n",
       "0  Would you like to take a look at the menu, sir...           \n",
       "1                    Help! Help!\\nWhat's the matter?           \n",
       "2  Whatever we do, we should do it above board.\\n...           \n",
       "3  May I see your passport, please?\\nCertainly. H...           \n",
       "4  We're thinking about going to America.\\nHave y...           \n",
       "5  Do you believe in UFOs?\\nOf course, they are o...           \n",
       "6  What do you think about the equipment in our c...           \n",
       "7  How was your business trip?\\nGreat - they wine...           \n",
       "8  Hello, Parker. How ’ s everything?\\nCan ’ t co...           \n",
       "9  Our toner cartridges are already out of ink......           \n",
       "\n",
       "           prediction  \n",
       "0          [FUN, FUN]  \n",
       "1  [NOT_FUN, NOT_FUN]  \n",
       "2          [FUN, FUN]  \n",
       "3  [NOT_FUN, NOT_FUN]  \n",
       "4  [NOT_FUN, NOT_FUN]  \n",
       "5          [FUN, FUN]  \n",
       "6  [NOT_FUN, NOT_FUN]  \n",
       "7          [FUN, FUN]  \n",
       "8          [FUN, FUN]  \n",
       "9  [NOT_FUN, NOT_FUN]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting point to note is that, due to the `position_debias_strategy=\"consensus\"`, if the order of the labels affects the result, `fastrepl` will return `None`. We'll be returning more meaningful value in the later version of `fastrepl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "first_result = [row[0] for row in result[\"prediction\"]]\n",
    "second_result = [row[1] for row in result[\"prediction\"]]\n",
    "\n",
    "print(first_result.count(None))\n",
    "print(second_result.count(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got some numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7241379310344828\n",
      "0.7241379310344828\n"
     ]
    }
   ],
   "source": [
    "def metric(result):\n",
    "    f = result.count(\"FUN\")\n",
    "    nf = result.count(\"NOT_FUN\")\n",
    "    return f / (f + nf)\n",
    "\n",
    "\n",
    "print(metric(first_result))\n",
    "print(metric(second_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
